---
layout: post
title: 嵩天老师爬虫前六单元小结
subtitle: 简单的记录
date: 2019-03-10
author: pacras
tags: 爬虫
---

# 第一单元 Requests库
&#160;&#160;&#160;&#160; 爬虫通用代码框架:

	import requests
	def getHTMLTest(url):
	    try:
	        r = requests.get(url)
	        r.raise\_for\_status()
		r.encoding = r.apparent\_endcoding()
	        return r.text
	except:
	    return “异常”

# 第二单元 爬虫协议
&#160;&#160;&#160;&#160;这一章主要讲了爬虫时应注意网站对爬虫的限制，可以在根目录下的 _robots.txt _文件中看到哪些网页是不能爬的。在爬取时应注意避免侵权，但是类人行为爬虫可以不做考虑。

# 第三单元 实战
&#160;&#160;&#160;&#160; 爬取图片，主要就是保存内容：

	with open('path', wb) as f:
	   f.write(r.content)
	    f.close()

# 第四单元 bs4库
&#160;&#160;&#160;&#160;可以使用 _Beautifu Soup_ 解析 HTML：
	soup = BeautifulSoup(html, ‘html_parser’)
&#160;&#160;&#160;&#160基本元素有 Tag、Name、Attributes、NavigableString、Comment。在遍历 html 时可以采用上行、下行和平行遍历。

# 第五单元 信息标记与提取
&#160;&#160;&#160;&#160;现在常用的信息标记格式有 Json、YAML和XML，其中XML常用语网络信息交互，较为繁琐；JSON常用于对接口进行处理，无注释；YAML可读性好常用于配置文件。
&#160;&#160;&#160;&#160在提取信息时，通常采取形式解析与搜索相结合的方式，例如提取页面中所有的URL链接，我们可以采取以下形式：
1. 搜索所有的 \<a\>标签 `find_all('a')`
2. 解析 \<a\> 格式，提取 _href_ 的内容 `get('href')`

# 第六单元 爬取大学排名 
&#160;&#160;&#160;&#160;我们要在最好大学网爬取软件工程专业的大学排名，分为三步：
1. 获取排名页面的的内容； _getHTMLText(url)_
2. 提取网页内容中的信息到合适的数据结构； _fillUnivList(ulist, html)_
3. 展示。_printUnivList(ulist, num)

&#160;&#160;&#160;&#160;每一步都对应一个函数，其中最关键的是 _fillUnivList(ulist, html)_，观察页面的 html 源码可知，整个排名信息在 *\<tbody\> *标签中，每个大学的信息在 *\<tr\>*标签中。
![][image-1] 

故可得代码：

	for tr in soup.find('tbody').children:
	   if isinstance(tr, bs4.element.Tag):
	        tds = tr('td')
	        #将内容保存到列表
	        ulist.append([tds[0].string, tds[1].string, tds[2].string])
	





[image-1]:	/img/inposts/%E7%88%AC%E8%99%AB1.jpg "html源码"